from .graph_state import AppState
from ..infrastructure.clients.llm_client import llm_client
from ..infrastructure.repositories.postgres_place_repo import PostgresPlaceRepository
from ..infrastructure.repositories.postgres_accommodation_repo import PostgresAccommodationRepository
from .services.planning_service import greedy_planner
from ..infrastructure.clients.osrm_client import osrm_client
from ..infrastructure.persistence.database import SessionLocal
from ..infrastructure.persistence.orm_models import Place

from ..infrastructure.clients.embedding_client import embedding_client
from .services.rerank_service import rerank_service
from .services.accommodation_recommendation_service import accommodation_recommendation_service

# æ–°å¢å°è©±ç›¸é—œå°å…¥
from ..domain.entities.conversation_state import ConversationState, ConversationStateType
from ..infrastructure.clients.gemini_llm_client import GeminiLLMClient
from typing import Optional
import redis
import json

class GraphNodes:
    """åŒ…å« LangGraph ä¸­æ‰€æœ‰ç¯€é»é‚è¼¯çš„é¡åˆ¥ - æ”¯æ´å°è©±å¼è¦åŠƒ"""
    
    def __init__(self):
        """åˆå§‹åŒ–å°è©±ç›¸é—œæœå‹™"""
        self.gemini_client = GeminiLLMClient()
        self.redis_client = redis.Redis(host='localhost', port=6379, db=0)
        
        # å®šç¾©éœ€è¦æ”¶é›†çš„è³‡è¨Š
        self.required_info = {
            "destination": "ç›®çš„åœ°",
            "duration": "æ—…éŠå¤©æ•¸", 
            "interests": "èˆˆè¶£é¡å‹",
            "budget": "é ç®—ç¯„åœ",
            "travel_style": "æ—…éŠé¢¨æ ¼",
            "group_size": "äººæ•¸",
            "transport_mode": "äº¤é€šå·¥å…·åå¥½"
        }

    def conversation_memory_manager(self, state: AppState) -> AppState:
        """ç¯€é»ï¼šå°è©±è¨˜æ†¶ç®¡ç†"""
        print("=" * 80)
        print("ğŸ” **NODE: conversation_memory_manager**")
        print("=" * 80)
        print(f"ğŸ“Š è¼¸å…¥ç‹€æ…‹: {state}")
        
        session_id = state.get("session_id", "")
        user_input = state.get("user_input", "")
        
        print(f"ğŸ†” Session ID: {session_id}")
        print(f"ğŸ’¬ User Input: {user_input}")
        
        # ç²å–æˆ–å‰µå»ºå°è©±ç‹€æ…‹
        conversation_state = self._get_conversation_state(session_id)
        if not conversation_state:
            conversation_state = ConversationState(session_id, ConversationStateType.COLLECTING_INFO)
            print("ğŸ†• å‰µå»ºæ–°çš„å°è©±ç‹€æ…‹")
        else:
            print(f"ğŸ“‹ ç²å–ç¾æœ‰å°è©±ç‹€æ…‹ï¼Œå·²é€²è¡Œ {conversation_state.turn_count} è¼ªå°è©±")
        
        # å¢åŠ å°è©±è¼ªæ¬¡
        conversation_state.increment_turn()
        
        # æ·»åŠ ç”¨æˆ¶è¨Šæ¯åˆ°æ­·å²
        conversation_state.add_message("user", user_input)
        print(f"ğŸ“ æ·»åŠ ç”¨æˆ¶è¨Šæ¯åˆ°æ­·å²")
        
        # æ›´æ–°ä¸Šä¸‹æ–‡è¨˜æ†¶
        conversation_state.add_context_memory(f"turn_{conversation_state.turn_count}_user", user_input)
        
        # ç”Ÿæˆä¸Šä¸‹æ–‡æ‘˜è¦
        context_summary = conversation_state.get_context_summary()
        
        # åˆ†æç”¨æˆ¶è¨Šæ¯ä¸¦æ›´æ–°æ”¶é›†çš„è³‡è¨Š
        print("ğŸ” é–‹å§‹åˆ†æç”¨æˆ¶è¨Šæ¯...")
        self._analyze_user_message_with_memory(conversation_state, user_input)
        print(f"ğŸ“Š åˆ†æå¾Œçš„è³‡è¨Š: {conversation_state.collected_info}")
        
        # æª¢æŸ¥æ˜¯å¦æ”¶é›†è¶³å¤ è³‡è¨Š
        is_complete = self._is_info_complete(conversation_state)
        print(f"âœ… è³‡è¨Šå®Œæ•´æ€§æª¢æŸ¥: {is_complete}")
        
        # ä¿å­˜ç‹€æ…‹
        self._save_conversation_state(conversation_state)
        print("ğŸ’¾ ä¿å­˜å°è©±ç‹€æ…‹")
        
        result = {
            **state,
            "conversation_state": conversation_state,
            "conversation_history": conversation_state.conversation_history,
            "collected_info": conversation_state.collected_info,
            "conversation_memory": conversation_state.conversation_memory,
            "context_summary": context_summary,
            "turn_count": conversation_state.turn_count,
            "is_info_complete": is_complete
        }
        
        print(f"ğŸ“Š ç•¶å‰å°è©±è¨˜æ†¶: {conversation_state.conversation_memory}")
        print(f"ğŸ“ ä¸Šä¸‹æ–‡æ‘˜è¦: {context_summary}")
        print(f"ğŸ“¤ è¼¸å‡ºç‹€æ…‹: {result}")
        print("=" * 80)
        
        return result

    def info_collector(self, state: AppState) -> AppState:
        """ç¯€é»ï¼šæ”¶é›†ç”¨æˆ¶è³‡è¨Š"""
        print("=" * 80)
        print("ğŸ” **NODE: info_collector**")
        print("=" * 80)
        print(f"ğŸ“Š è¼¸å…¥ç‹€æ…‹: {state}")
        
        conversation_state = state.get("conversation_state")
        if not conversation_state:
            print("âŒ æ²’æœ‰æ‰¾åˆ°å°è©±ç‹€æ…‹")
            return {**state, "error": "Conversation state not found."}
        
        print(f"ğŸ“‹ å°è©±ç‹€æ…‹: {conversation_state.state.value}")
        print(f"ğŸ“Š æ”¶é›†çš„è³‡è¨Š: {conversation_state.collected_info}")
        
        # å¦‚æœè³‡è¨Šå®Œæ•´ï¼Œç›´æ¥è¿”å›
        if state.get("is_info_complete", False):
            print("âœ… è³‡è¨Šå·²å®Œæ•´ï¼Œè·³éå•é¡Œç”Ÿæˆ")
            return state
        
        print("â“ è³‡è¨Šä¸å®Œæ•´ï¼Œç”Ÿæˆä¸‹ä¸€å€‹å•é¡Œ...")
        
        # ç”Ÿæˆä¸‹ä¸€å€‹å•é¡Œ
        next_question = self._generate_next_question_with_memory(conversation_state)
        print(f"ğŸ¤– ç”Ÿæˆçš„å•é¡Œ: {next_question}")
        
        # æ·»åŠ  AI å›æ‡‰åˆ°æ­·å²
        conversation_state.add_message("assistant", next_question)
        print("ğŸ“ æ·»åŠ  AI å›æ‡‰åˆ°æ­·å²")
        
        # ä¿å­˜ç‹€æ…‹
        self._save_conversation_state(conversation_state)
        print("ğŸ’¾ ä¿å­˜å°è©±ç‹€æ…‹")
        
        result = {
            **state,
            "ai_response": next_question,
            "next_question": next_question,
            "conversation_state": conversation_state
        }
        
        print(f"ğŸ“¤ è¼¸å‡ºç‹€æ…‹: {result}")
        print("=" * 80)
        
        return result

    def extract_story(self, state: AppState) -> AppState:
        """ç¯€é»ï¼šå¾æ”¶é›†çš„è³‡è¨Šæå– Story"""
        print("=" * 80)
        print("ğŸ” **NODE: extract_story**")
        print("=" * 80)
        print(f"ğŸ“Š è¼¸å…¥ç‹€æ…‹: {state}")
        
        # æª¢æŸ¥æ˜¯å¦è³‡è¨Šå®Œæ•´
        if not state.get("is_info_complete", False):
            print("âŒ è³‡è¨Šä¸å®Œæ•´ï¼Œç„¡æ³•æå– Story")
            return {**state, "error": "Information not complete yet."}
        
        collected_info = state.get("collected_info", {})
        print(f"ğŸ“Š æ”¶é›†çš„è³‡è¨Š: {collected_info}")
        
        # åŸºæ–¼æ”¶é›†çš„è³‡è¨Šæ§‹å»º Story
        destination = collected_info.get("destination", "å®œè˜­")
        duration = collected_info.get("duration", "1å¤©")
        interests = collected_info.get("interests", ["ç¾é£Ÿ"])
        
        # æ§‹å»ºè¦åŠƒæ–‡å­—
        planning_text = f"æˆ‘æƒ³è¦åœ¨{destination}é€²è¡Œ{duration}çš„æ—…éŠï¼ŒåŒ…å«{', '.join(interests)}"
        print(f"ğŸ“ æ§‹å»ºçš„è¦åŠƒæ–‡å­—: {planning_text}")
        
        # ä½¿ç”¨åŸæœ‰çš„ LLM æå– Story
        print("ğŸ¤– é–‹å§‹æå– Story...")
        story = llm_client.extract_story_from_text(planning_text)
        print(f"ğŸ“Š Story è§£æçµæœ: days={story.days}, start={story.daily_window.start if story.daily_window else 'None'}, end={story.daily_window.end if story.daily_window else 'None'}")
        
        if story.days == 0:
            print("âŒ Story å¤©æ•¸ç‚º 0ï¼Œè³‡è¨Šä¸è¶³")
            return {**state, "error": "Information insufficient."}
        
        result = {**state, "story": story}
        print(f"ğŸ“¤ è¼¸å‡ºç‹€æ…‹: {result}")
        print("=" * 80)
        
        return result

    def retrieve_places_structured(self, state: AppState) -> AppState:
        """ç¯€é»ï¼šçµæ§‹åŒ–æª¢ç´¢åœ°é»"""
        print("--- Node: retrieve_places_structured ---")
        story = state.get("story")
        if not story:
            return {**state, "error": "Story not found."}

        db = SessionLocal()
        repo = PostgresPlaceRepository(db)
        structured_results = repo.search(categories=story.preference.themes)
        db.close()
        
        print(f"Found {len(structured_results)} candidates from structured search.")
        return {**state, "structured_candidates": structured_results}

    def retrieve_places_semantic(self, state: AppState) -> AppState:
        """ç¯€é»ï¼šèªç¾©åŒ–æª¢ç´¢åœ°é»"""
        print("--- Node: retrieve_places_semantic ---")
        story = state.get("story")
        if not story:
            return {**state, "error": "Story not found."}

        # å°‡åå¥½ä¸»é¡Œåˆä½µç‚ºä¸€å€‹æŸ¥è©¢å­—ä¸²
        query_text = " ".join(story.preference.themes)
        query_embedding = embedding_client.get_embedding(query_text)

        db = SessionLocal()
        repo = PostgresPlaceRepository(db)
        semantic_results = repo.search_by_vector(query_embedding)
        db.close()

        print(f"Found {len(semantic_results)} candidates from semantic search.")
        return {**state, "semantic_candidates": semantic_results}

    def rank_and_merge(self, state: AppState) -> AppState:
        """ç¯€é»ï¼šèåˆä¸¦é‡æ’åºå€™é¸åœ°é»"""
        print("--- Node: rank_and_merge ---")
        story = state.get("story")
        structured = state.get("structured_candidates", [])
        semantic = state.get("semantic_candidates", [])

        if not story:
            return {**state, "error": "Story not found."}

        final_candidates = rerank_service.rerank(structured, semantic, story)
        print(f"Reranked and merged into {len(final_candidates)} final candidates.")
        return {**state, "candidates": final_candidates}

    def retrieve_accommodations(self, state: AppState) -> AppState:
        """ç¯€é»ï¼šæª¢ç´¢ä½å®¿"""
        print("--- Node: retrieve_accommodations ---")
        story = state.get("story")
        if not story:
            return {**state, "error": "Story not found."}

        db = SessionLocal()
        repo = PostgresAccommodationRepository(db)
        
        # æ ¹æ“š Story ä¸­çš„ä½å®¿åå¥½æª¢ç´¢
        accommodations = repo.search(
            accommodation_type=story.accommodation.type,
            budget_range=story.accommodation.budget_range,
            eco_friendly="ç’°ä¿" in getattr(story, 'special_requirements', ''),
            min_rating=4.0  # æœ€ä½4æ˜Ÿè©•åˆ†
        )
        
        db.close()
        
        print(f"Found {len(accommodations)} accommodation candidates.")
        return {**state, "accommodation_candidates": accommodations}

    def plan_itinerary(self, state: AppState) -> AppState:
        """ç¯€é»ï¼šè¦åŠƒè¡Œç¨‹ï¼ˆæ•´åˆäº¤é€šå·¥å…·åå¥½ï¼‰"""
        print("--- Node: plan_itinerary (Enhanced with Transport) ---")
        story = state.get("story")
        candidates = state.get("candidates")
        accommodation_candidates = state.get("accommodation_candidates", [])
        conversation_state = state.get("conversation_state")

        if not story or not candidates:
            return {**state, "error": "Story or candidates not found."}

        # å–å¾—äº¤é€šå·¥å…·åå¥½
        transport_mode = "mixed"  # é è¨­å€¼
        if conversation_state and conversation_state.collected_info:
            transport_mode = conversation_state.collected_info.get("transport_mode", "mixed")
        
        print(f"ğŸš— äº¤é€šå·¥å…·åå¥½: {transport_mode}")

        # ä½¿ç”¨å¢å¼·ç‰ˆè¦åŠƒæœå‹™
        try:
            from .services.enhanced_planning_service import EnhancedPlanningService
            from .services.bus_routing_service import BusRoutingService
            
            # å»ºç«‹å¢å¼·ç‰ˆè¦åŠƒæœå‹™
            enhanced_planner = EnhancedPlanningService()
            
            # è¦åŠƒè¡Œç¨‹ï¼ˆåŒ…å«äº¤é€šï¼‰
            itinerary = enhanced_planner.plan_itinerary_with_transport(
                story, candidates, user_transport_choice=transport_mode
            )
            
            print(f"âœ… å¢å¼·ç‰ˆè¡Œç¨‹è¦åŠƒå®Œæˆï¼ŒåŒ…å« {len(itinerary.days)} å¤©è¡Œç¨‹")
            
        except Exception as e:
            print(f"âš ï¸ å¢å¼·ç‰ˆè¦åŠƒå¤±æ•—ï¼Œå›é€€åˆ°åŸºç¤è¦åŠƒ: {e}")
            
            # å›é€€åˆ°åŸå§‹è¦åŠƒæ–¹æ³•
            from sqlalchemy import func
            db = SessionLocal()
            try:
                place_ids = [str(p.id) for p in candidates]
                results = db.query(
                    Place.id,
                    func.ST_Y(Place.geom).label('lat'),
                    func.ST_X(Place.geom).label('lon')
                ).filter(Place.id.in_(place_ids)).all()
                
                coord_map = {str(r.id): (r.lon, r.lat) for r in results}
                locations = [coord_map[str(p.id)] for p in candidates if str(p.id) in coord_map]
            finally:
                db.close()
            
            import asyncio
            travel_matrix = asyncio.run(osrm_client.get_travel_time_matrix(locations))
            
            if not travel_matrix:
                return {**state, "error": "Failed to get travel time matrix."}
            
            itinerary = greedy_planner.plan(story, candidates, travel_matrix)
        
        # æ·»åŠ ä½å®¿æ¨è–¦
        if accommodation_candidates:
            itinerary.days = accommodation_recommendation_service.recommend_accommodations_for_days(
                itinerary.days, accommodation_candidates, story
            )
        
        # æ·»åŠ äº¤é€šæ‘˜è¦åˆ°è¡Œç¨‹
        self._add_transport_summary_to_itinerary(itinerary, transport_mode)
        
        print("Planning complete with transport integration.")
        
        return {**state, "itinerary": itinerary, "transport_mode": transport_mode}

    def _add_transport_summary_to_itinerary(self, itinerary, transport_mode):
        """ç‚ºè¡Œç¨‹æ·»åŠ äº¤é€šæ‘˜è¦"""
        try:
            transport_mode_names = {
                "driving": "é–‹è»Š",
                "public_transport": "å¤§çœ¾é‹è¼¸",
                "mixed": "æ··åˆäº¤é€š",
                "eco_friendly": "ç’°ä¿å‡ºè¡Œ"
            }
            
            mode_name = transport_mode_names.get(transport_mode, "æ··åˆäº¤é€š")
            
            # è¨ˆç®—ç¸½äº¤é€šçµ±è¨ˆ
            total_cost = 0.0
            total_duration = 0
            transport_segments = 0
            
            for day in itinerary.days:
                for visit in day.visits:
                    if hasattr(visit.place, 'description') and visit.place.description:
                        # æª¢æŸ¥æ˜¯å¦åŒ…å«äº¤é€šè³‡è¨Š
                        if "äº¤é€šè³‡è¨Š:" in visit.place.description:
                            transport_segments += 1
                            # ç°¡å–®è§£æè²»ç”¨ï¼ˆå¯¦éš›æ‡‰ç”¨ä¸­éœ€è¦æ›´è¤‡é›œçš„è§£æï¼‰
                            if "è²»ç”¨:" in visit.place.description:
                                try:
                                    cost_part = visit.place.description.split("è²»ç”¨: $")[1].split(")")[0]
                                    total_cost += float(cost_part)
                                except:
                                    pass
            
            # æ·»åŠ è¡Œç¨‹æ‘˜è¦
            summary = f"\n\nğŸ“Š äº¤é€šè¦åŠƒæ‘˜è¦:\n"
            summary += f"ä¸»è¦äº¤é€šæ–¹å¼: {mode_name}\n"
            if transport_segments > 0:
                summary += f"äº¤é€šè·¯æ®µæ•¸: {transport_segments}\n"
                if total_cost > 0:
                    summary += f"é ä¼°äº¤é€šè²»ç”¨: ${total_cost:.0f}\n"
            
            # æ·»åŠ äº¤é€šå»ºè­°
            if transport_mode == "driving":
                summary += "ğŸ’¡ å»ºè­°: æå‰ç¢ºèªåœè»Šè³‡è¨Šï¼Œæ³¨æ„è·¯æ³\n"
            elif transport_mode == "public_transport":
                summary += "ğŸ’¡ å»ºè­°: æº–å‚™é›¶éŒ¢æˆ–æ‚ éŠå¡ï¼Œæ³¨æ„ç­æ¬¡æ™‚é–“\n"
            elif transport_mode == "mixed":
                summary += "ğŸ’¡ å»ºè­°: æ™ºèƒ½é¸æ“‡æœ€ä½³äº¤é€šæ–¹å¼ï¼Œå½ˆæ€§èª¿æ•´\n"
            elif transport_mode == "eco_friendly":
                summary += "ğŸ’¡ å»ºè­°: ç’°ä¿å‡ºè¡Œï¼Œå»ºè­°æ”œå¸¶ç’°ä¿ç”¨å“\n"
            
            # æ·»åŠ åˆ°è¡Œç¨‹æè¿°
            if hasattr(itinerary, 'description'):
                itinerary.description = (itinerary.description or "") + summary
            else:
                itinerary.description = summary
                
        except Exception as e:
            print(f"æ·»åŠ äº¤é€šæ‘˜è¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    # å°è©±ç›¸é—œçš„è¼”åŠ©æ–¹æ³•
    def _get_conversation_state(self, session_id: str) -> Optional[ConversationState]:
        """ç²å–å°è©±ç‹€æ…‹"""
        try:
            state_data = self.redis_client.get(f"conversation:{session_id}")
            if state_data:
                return ConversationState.from_dict(json.loads(state_data))
            return None
        except Exception as e:
            print(f"Error getting conversation state: {e}")
            return None
    
    def _save_conversation_state(self, state: ConversationState):
        """ä¿å­˜å°è©±ç‹€æ…‹"""
        try:
            self.redis_client.setex(
                f"conversation:{state.session_id}", 
                3600,  # 1å°æ™‚éæœŸ
                json.dumps(state.to_dict())
            )
        except Exception as e:
            print(f"Error saving conversation state: {e}")
    
    def _analyze_user_message_with_memory(self, state: ConversationState, message: str):
        """åŸºæ–¼è¨˜æ†¶åˆ†æç”¨æˆ¶è¨Šæ¯"""
        
        # æ§‹å»ºåŒ…å«è¨˜æ†¶çš„æç¤ºè©
        memory_context = ""
        if state.conversation_memory:
            memory_context = f"""
            å°è©±è¨˜æ†¶:
            {json.dumps(state.conversation_memory, ensure_ascii=False, indent=2)}
            """
        
        # ä½¿ç”¨ LLM åˆ†æç”¨æˆ¶è¨Šæ¯
        analysis_prompt = f"""
        åˆ†æç”¨æˆ¶çš„è¨Šæ¯ï¼Œæå–æ—…éŠè¦åŠƒç›¸é—œè³‡è¨Šã€‚
        
        {memory_context}
        
        ç”¨æˆ¶ç•¶å‰è¨Šæ¯: {message}
        
        è«‹å¾ä»¥ä¸‹é¡åˆ¥ä¸­è­˜åˆ¥ä¸¦æå–è³‡è¨Šï¼š
        - destination: ç›®çš„åœ° (å¦‚: å®œè˜­ã€å°åŒ—ã€èŠ±è“®)
        - duration: æ—…éŠå¤©æ•¸ (å¦‚: 1å¤©ã€2å¤©1å¤œã€3å¤©2å¤œ)
        - interests: èˆˆè¶£é¡å‹ (å¦‚: ç¾é£Ÿã€é¢¨æ™¯ã€æ–‡åŒ–ã€è³¼ç‰©)
        - budget: é ç®—ç¯„åœ (å¦‚: ä½ã€ä¸­ã€é«˜)
        - travel_style: æ—…éŠé¢¨æ ¼ (å¦‚: è¼•é¬†ã€ç·Šæ¹Šã€æ·±åº¦)
        - group_size: äººæ•¸ (å¦‚: 1äººã€2äººã€å®¶åº­)
        
        è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼ŒåªåŒ…å«è­˜åˆ¥åˆ°çš„è³‡è¨Šã€‚å¦‚æœæ²’æœ‰è­˜åˆ¥åˆ°ä»»ä½•è³‡è¨Šï¼Œè«‹è¿”å›ç©ºçš„ JSON ç‰©ä»¶ {{}}ã€‚
        ç¯„ä¾‹: {{"destination": "å®œè˜­", "duration": "2å¤©1å¤œ", "interests": ["ç¾é£Ÿ", "é¢¨æ™¯"]}}
        """
        
        try:
            analysis = self.gemini_client.generate_text(analysis_prompt)
            print(f"ğŸ” åŸºæ–¼è¨˜æ†¶çš„åˆ†æçµæœ: {analysis}")
            
            # å˜—è©¦è§£æ JSON å›æ‡‰
            try:
                extracted_info = json.loads(analysis)
            except json.JSONDecodeError:
                # å¦‚æœ JSON è§£æå¤±æ•—ï¼Œå˜—è©¦æå– JSON éƒ¨åˆ†
                import re
                # è™•ç† ```json æ¨™è¨˜
                json_match = re.search(r'```json\s*(\{.*?\})\s*```', analysis, re.DOTALL)
                if json_match:
                    extracted_info = json.loads(json_match.group(1))
                else:
                    # å˜—è©¦æå–ç´” JSON
                    json_match = re.search(r'\{.*\}', analysis, re.DOTALL)
                    if json_match:
                        extracted_info = json.loads(json_match.group())
                    else:
                        print(f"âŒ ç„¡æ³•è§£æ JSON: {analysis}")
                        extracted_info = {}
            
            # æ›´æ–°æ”¶é›†çš„è³‡è¨Š
            for key, value in extracted_info.items():
                if key in self.required_info:
                    state.add_info(key, value)
                    
        except Exception as e:
            print(f"Error analyzing user message with memory: {e}")
            # å‚™ç”¨æ–¹æ¡ˆï¼šç°¡å–®é—œéµå­—åŒ¹é…
            self._fallback_keyword_analysis(state, message)
    
    def _fallback_keyword_analysis(self, state: ConversationState, message: str):
        """å‚™ç”¨é—œéµå­—åˆ†æ"""
        if "å®œè˜­" in message:
            state.add_info("destination", "å®œè˜­")
        if "å°åŒ—" in message:
            state.add_info("destination", "å°åŒ—")
        if "èŠ±è“®" in message:
            state.add_info("destination", "èŠ±è“®")
        if "é«˜é›„" in message:
            state.add_info("destination", "é«˜é›„")
        if "1å¤©" in message or "ä¸€å¤©" in message:
            state.add_info("duration", "1å¤©")
        if "2å¤©" in message or "å…©å¤©" in message:
            state.add_info("duration", "2å¤©1å¤œ")
        if "3å¤©" in message or "ä¸‰å¤©" in message:
            state.add_info("duration", "3å¤©2å¤œ")
        if "ç¾é£Ÿ" in message:
            if "interests" not in state.collected_info:
                state.collected_info["interests"] = []
            if "ç¾é£Ÿ" not in state.collected_info["interests"]:
                state.collected_info["interests"].append("ç¾é£Ÿ")
        if "é¢¨æ™¯" in message or "è‡ªç„¶" in message:
            if "interests" not in state.collected_info:
                state.collected_info["interests"] = []
            if "è‡ªç„¶é¢¨æ™¯" not in state.collected_info["interests"]:
                state.collected_info["interests"].append("è‡ªç„¶é¢¨æ™¯")
        
        # äº¤é€šå·¥å…·åå¥½é—œéµå­—
        if "é–‹è»Š" in message or "è‡ªé§•" in message or "æ±½è»Š" in message:
            state.add_info("transport_mode", "driving")
        elif "å¤§çœ¾é‹è¼¸" in message or "å…¬è»Š" in message or "ç«è»Š" in message or "æ·é‹" in message:
            state.add_info("transport_mode", "public_transport")
        elif "ç’°ä¿" in message or "ç¶ è‰²" in message or "ä½ç¢³" in message:
            state.add_info("transport_mode", "eco_friendly")
        elif "æ··åˆ" in message or "å½ˆæ€§" in message or "æ™ºèƒ½" in message:
            state.add_info("transport_mode", "mixed")
    
    def _is_info_complete(self, state: ConversationState) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ”¶é›†è¶³å¤ çš„è³‡è¨Š"""
        # è‡³å°‘éœ€è¦ç›®çš„åœ°å’Œå¤©æ•¸
        essential_keys = ["destination", "duration"]
        return all(key in state.collected_info for key in essential_keys)
    
    def _generate_next_question_with_memory(self, state: ConversationState) -> str:
        """åŸºæ–¼è¨˜æ†¶ç”Ÿæˆä¸‹ä¸€å€‹å•é¡Œ"""
        
        # æ§‹å»ºè¨˜æ†¶ä¸Šä¸‹æ–‡
        memory_context = ""
        if state.conversation_memory:
            memory_context = f"""
            å°è©±è¨˜æ†¶:
            {json.dumps(state.conversation_memory, ensure_ascii=False, indent=2)}
            """
        
        # æ‰¾å‡ºé‚„éœ€è¦æ”¶é›†çš„è³‡è¨Š
        missing_info = []
        for key, label in self.required_info.items():
            if key not in state.collected_info:
                missing_info.append(label)
        
        # ç”Ÿæˆå•é¡Œ
        question_prompt = f"""
        åŸºæ–¼å·²æ”¶é›†çš„è³‡è¨Šã€å°è©±è¨˜æ†¶å’Œå°è©±æ­·å²ï¼Œç”Ÿæˆä¸€å€‹è‡ªç„¶çš„å•é¡Œä¾†æ”¶é›†æ›´å¤šæ—…éŠè¦åŠƒè³‡è¨Šã€‚
        
        {memory_context}
        
        å·²æ”¶é›†çš„è³‡è¨Š: {json.dumps(state.collected_info, ensure_ascii=False)}
        é‚„éœ€è¦æ”¶é›†: {', '.join(missing_info)}
        å°è©±æ­·å²: {json.dumps(state.conversation_history[-3:], ensure_ascii=False)}
        
        ç‰¹åˆ¥æ³¨æ„ï¼š
        - å¦‚æœéœ€è¦æ”¶é›†äº¤é€šå·¥å…·åå¥½ï¼Œè«‹æä¾›é¸é …ï¼šé–‹è»Šã€å¤§çœ¾é‹è¼¸ã€æ··åˆæ¨¡å¼ã€ç’°ä¿å‡ºè¡Œ
        - å¦‚æœæ˜¯äº¤é€šå·¥å…·åå¥½å•é¡Œï¼Œè«‹èªªæ˜å„é¸é …çš„ç‰¹é»
        - æ ¹æ“šç›®çš„åœ°å’Œèˆˆè¶£é¡å‹æ¨è–¦åˆé©çš„äº¤é€šæ–¹å¼
        
        è«‹ç”Ÿæˆä¸€å€‹å‹å–„ã€è‡ªç„¶çš„å•é¡Œï¼Œå¹«åŠ©æ”¶é›†æ—…éŠè¦åŠƒè³‡è¨Šã€‚
        å›æ‡‰æ ¼å¼: ç›´æ¥è¿”å›å•é¡Œæ–‡å­—ï¼Œä¸è¦å…¶ä»–å…§å®¹ã€‚
        """
        
        try:
            question = self.gemini_client.generate_text(question_prompt)
            return question.strip()
            
        except Exception as e:
            print(f"Error generating question with memory: {e}")
            return "è«‹å‘Šè¨´æˆ‘æ‚¨æƒ³å»å“ªè£¡æ—…éŠå‘¢ï¼Ÿ"
